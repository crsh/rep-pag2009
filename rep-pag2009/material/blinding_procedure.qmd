---
title: "Blinding procedure"
author: "Frederik Aust"
date: "`r Sys.Date()`"

toc: true
number-sections: true
reference-location: margin

highlight-style: github
theme: lumen

execute:
  keep-md: true

format:
  html:
    code-fold: true
    standalone: true
    embed-resources: true
    self-contained: true
    link-external-icon: true
    citations-hover: true
    footnotes-hover: true
---

```{r}
#| label: init
#| include: false

library("dplyr")
library("ggplot2")
library("patchwork")
library("ggforce")
library("brms")
```

# Introduction



## Experimental procedure

![Experimental procedure](./procedure.png)

The design of the study involves two factors and one continuous covariate:

1. **Condition**: The first factor was experimentally manipulated within subject. It related to whether participants made their prediction prior to or after seeing the outcome of the coin flip. Hence, this factor manipulated whether there was an `op`portunity or `noop`portunity to cheat.
2. **Correct**: The second factor was measured and related to whether participant's prediction was correct (`win`) or incorrect (`loss`).
3. **Dishonesty**: The continuous covariate was a measured index of participtans willingness to dishonestly claim a reward and was measured as the proportion of trials in which participants had the opportunity to cheat and claimed a reward.

We will examine the effect of these predictors on three outcomes:

1. Response times
2. fMRI BOLD signal in the dorso-lateral prefrontal cortex (DLPFC)
3. fMRI BOLD signal in the anterior cingulate cortex (ACC)

## Blinding procedure

To conduct the preregistered sequential blinded analysis, we sought to devise a procedure that meets the following criteria.
The blinded data should

1. retain information about the shape of the distribution of the data to inform our choice of the appropriate distributional assumptions in our analytic model,
2. retain information about participants variability around the average effects to facilitate devising appropriate weakling regularizing priors on the random effect variances in our analytic model (we do not seek to test hypotheses about the structure or magnitude of the individual differences and we are unaware of any previously published estimates in the literature that could inform our priors),
3. obfuscate mean differences between the experimental conditions, and
4. obfuscate the relationship between dishonesty and mean differences between the experimental conditions.

To meet these criteria, obfuscation of the differences between experimental conditions by equalizing cell means (Dutilh, Sarafoglou, & Wagenmakers, 2021).
fMRI bold signals can be assumed to be approximately normally distributed.
Hence, equalizing cell means is straight forward.
We will simply add a constant to each observation, such that each condition mean is equal to the grand average across all conditions.

Equalizing cell means is more challenging for response times:
Because means and variances of response time distributions are positively linearly related (Wagenmakers et al., 2007), equalizing cell *means* by adding a constant does not prevent reconstruction of the order of cell means from their standard deviations.
To address this issue, we will approximately equalize cell medians by multiplying each oberservation by a fixed factor, such that each condition median is approximately equal to the grand median across all conditions and the standard deviations will be scaled accordingly.

However the blinding of response times is additionally complicated by non-decision times in processing the stimulus display and executing the response are known to yield a shift in the response time distribution.
Such shifts would also be scaled by simply multiplying the response times by a fixed factor.
However, leaveing non-decision times approximately intact could help devise inform possible exclusion rules for too fast responses and devise regularizing priors to facilitate the estimation of our hierarchical Bayesian model.
We will therefore estimate each participants non-decision time in a hierarchical log-normal model to equalize only the medians of the decision time.
Specifically, we will subtract estimates of individual non-decision times from the respective response time distributions before equalizing their medians and finally adding individual non-decision times back in.
We choose the shifted log-normal distribution for this because it provides a good fit to the distribution response times (Rouder et al, 2015).

Finally, we will shuffle the values of the dishonesty covariate to obfuscate the relationship between dishonesty and the experimental conditions.

To demonstrate the general approach I will first apply the blinding procedure to the pilot data from a single subject.
I will then show how to extend the procedure to hierachical data from multiple participants

# Pilot data showcase

```{r}
#| label: load-pilot-data

data(pilot, package = "reppag2009")
```

## Equalizing fMRI bold signal

First, consider the fMRI bold signal measured on each trial in the DLPFC and ACC shown in @fig-pilot-data-fmri A.
In line with typical assumptions, the distributions appear symmetric.
Because the research question concerns the effect of the experimental manipulation on the average bold signal, I opted to equalize the condition means by adding a constant to each observation such that the condition means are identical.

@fig-pilot-data-fmri B show the equalized condition means in the blinded data.
Note that the blinded data retains the shape of the distributions as well as differences in the spread of the distribution across conditions.
This information can inform the choice of the appropriate modelling assumptions.

```{r}
#| label: equalize-pilot-fmri

fmri_equalizer <- pilot |>
  dplyr::summarize(
    acc_mean = mean(acc_activity)
    , dlpfc_mean = mean(dlpfc_activity)
    , .by = c("condition", "correct")
) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    acc_offset = acc_mean - mean(acc_mean)
    , dlpfc_offset = dlpfc_mean - mean(dlpfc_mean)
  ) |>
  dplyr::select(-acc_mean, -dlpfc_mean)

blinded_pilot <- pilot |>
  dplyr::left_join(
    fmri_equalizer
    , by = c("correct", "condition")
  ) |>
  dplyr::mutate(
    acc_activity = acc_activity - acc_offset
    , dlpfc_activity = dlpfc_activity - dlpfc_offset
  )
```

```{r}
#| label: fig-pilot-data-fmri
#| fig-cap: "fMRI bold signal in the DLPFC and ACC of one pilot participant. (A) Unblinded data and (B) blinded data with equalized condition means. Points represent condition means and error bars standard deviations. The dashed vertical line represents the grand mean."

pilot_plot <- list(
  geom_violin()
  , stat_summary(geom = "vline", aes(y = 0, xintercept = after_stat(x), group = 1), fun = mean, linetype = "22", orientation = "y")
  , geom_sina()
  , stat_summary(geom = "pointrange", fun.data = mean_sdl, fun.args = list(mult = 1), shape = 21, position = position_dodge(0.9), size = 1.25, color = "white")
)

dlpfc_plot <- ggplot(pilot) +
  aes(x = dlpfc_activity, y = condition, fill = correct) +
  pilot_plot +
  xlim(-8, 8) +
  labs(x = "DLPFC bold signal", y = "Condition")

acc_plot <- ggplot(pilot) +
  aes(x = acc_activity, y = condition, fill = correct) +
  pilot_plot +
  xlim(-3.25, 3.25) +
  labs(x = "ACC bold signal", y = "Condition")

blinded_dlpfc_plot <- ggplot(blinded_pilot) +
  aes(x = dlpfc_activity, y = condition, fill = correct) +
  pilot_plot +
  xlim(-8, 8) +
  labs(x = "DLPFC bold signal", y = "Condition")

blinded_acc_plot <- ggplot(blinded_pilot) +
  aes(x = acc_activity, y = condition, fill = correct) +
  pilot_plot +
  xlim(-3.25, 3.25) +
  labs(x = "ACC bold signal", y = "Condition")

dlpfc_plot + acc_plot +
  blinded_dlpfc_plot + blinded_acc_plot + 
  plot_layout(design = "AB\nCD", guides = "collect") +
  plot_annotation(tag_levels = list(c("A", "", "B", "")))
```

## Equalizing response times

@fig-pilot-data-rt A shows the distribution of response times in the pilot data.
The response time distributions are positively skewed and the unblinded data exhibit some variation in condition means.
To equalize condition means, I fit a log-normal model to the response times.

### Review of the log-normal distribution

A three-parameter log-normal distributed variable, $y \sim \log\mathcal{N}(\mu, \sigma, \delta)$, is parameterized the shift $\delta$, which shifts the distribution by a constant value without affecting its shape, as well as the mean $\mu$ and the standard deviation $\sigma$ of the unshifted distribution---that is, $\log(y - \delta) \sim \mathcal{N}(\mu, \sigma)$, @fig-lognormal-distribution.

```{r}
#| label: fig-lognormal-distribution
#| fig-cap: "Effects decision time ($\\mu$, $\\sigma$) and non-decision time parameters ($\\delta$) on the location and shape of the three-parameter log-normal distribution."
#| fig-height: 2
#| fig-width: 6

cols <- viridisLite::plasma(2, begin = 0.2, end = 0.8)
linewidth <- 3

layout(matrix(1:3, nrow = 1))

par(mar = c(3, 0, 4, 0))
curve(
  brms::dshifted_lnorm(x, meanlog = 0.5, sdlog = 0.5, shift = 0.2)
  , from = 0, to = 7
  , axes = FALSE
  , xlab = NA
  , ylab = NA
  , lwd = linewidth
  , col = cols[1]
  , cex.lab = 1.5
)

curve(
  brms::dshifted_lnorm(x, meanlog = 1, sdlog = 0.5, shift = 0.2)
  , add = TRUE
  , lwd = linewidth
  , col = cols[2]
)

mtext(bquote(mu), side = 1, line = 1)

curve(
  brms::dshifted_lnorm(x, meanlog = 0.7, sdlog = 0.5, shift = 0.2)
  , from = 0, to = 7
  , axes = FALSE
  , xlab = NA
  , ylab = NA
  , lwd = linewidth
  , col = cols[1]
  , cex.lab = 1.5
)

curve(
  brms::dshifted_lnorm(x, meanlog = 0.7, sdlog = 1, shift = 0.2)
  , add = TRUE
  , lwd = linewidth
  , col = cols[2]
)

mtext(bquote(sigma), side = 1, line = 1)

mtext("Decision time", side = 3, line = 1.5, at = -0.25, cex = 1)

curve(
  brms::dshifted_lnorm(x, meanlog = 0.7, sdlog = 0.5, shift = 0.2)
  , from = 0, to = 7
  , axes = FALSE
  , xlab = NA
  , ylab = NA
  , lwd = linewidth
  , col = cols[1]
  , cex.lab = 1.5
)

curve(
  brms::dshifted_lnorm(x, meanlog = 0.7, sdlog = 0.5, shift = 1)
  , add = TRUE
  , lwd = linewidth
  , col = cols[2]
)

mtext(bquote(delta), side = 1, line = 1)

mtext("Non-decision time", side = 3, line = 1.5, at = 3.5, cex = 1)
```

Applied to response time data, the shift $\delta$ represents a constant non-decision time, the mean $\mu$ the average decision time, and the standard deviation $\sigma$ the variability in the decision time.
With respect to the distributions central tendencies, increases in $\mu$ produce increases in the mean and median of the distribution, whereas increases in $\sigma$ produce increases in the mean of the skewed distribution but not the median.
The median of the log-normal distribution is given by $\exp(\mu) + \delta$.
Increases in both $\mu$ and $\sigma$ produce increases in the spread of the distribution.

### Equalization strategy

In the log-normal model of response times, increases in decision time should be reflected in $\mu$.
Hence, I opted to equalize $\mu$ across conditions.
In estimating $\mu$ I assumed $\sigma$ and $\delta$ to be constant and, thus, they were not equalized.
Thus, the blinded data retains the shape of the distributions as well as differences in the spread of the distribution across conditions.
This information can inform the choice of the appropriate modelling assumptions.

```{r}
#| label: equalize-pilot-rt
#| cache: true

mod_pilot <- brm(
  formula = rt ~ correct * condition
  , data = pilot
  , family = brms::shifted_lognormal
  , chains = 4
  , cores = 2
  , iter = 2000
  , warmup = 1000
  , thin = 1
  , seed = 123
  , verbose = FALSE
)

naive_rt_equalizer <- pilot |>
  dplyr::summarize(
    rt_mean = mean(rt)
    , .by = c("condition", "correct")
  ) |>
  dplyr::mutate(
    rt_offset = rt_mean - mean(rt_mean)
  ) |>
  dplyr::select(-rt_mean)

rt_equalizer <- tidybayes::epred_draws(
  mod_pilot
  , dpar = c(mu = "mu", ndt = "ndt")
  , newdata = pilot[, c("condition", "correct")] |> unique()
  , re_formula = NULL
) |>
  dplyr::summarize(
    mu = median(mu)
    , ndt = median(ndt)
  ) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    mu_offset = mu - mean(mu)
  ) |>
  dplyr::select(-mu)

blinded_pilot <- pilot |>
  dplyr::left_join(
    naive_rt_equalizer
    , by = c("correct", "condition")
  ) |>
  dplyr::left_join(
    rt_equalizer
    , by = c("correct", "condition")
  ) |>
  dplyr::mutate(
    naive_rt = rt - rt_offset
    , log_rt = log(rt - ndt)
    , log_rt = log_rt - mu_offset
    , rt = exp(log_rt) + ndt
  )
```

@fig-pilot-data-rt B and C show the effects of a simple blinding procedure that equalizes condition means and the more sophisticated procedure---based on the log-normal distribution---that equalizes $\hat\mu$.
A few things are worth noting.
First, owing to the skewed distributions, the simple blinding procedure equalizes the condition means but does not equalize the medians, @fig-pilot-data-rt B.
The simple blinding procedure also does not affect the spread of the distributions across conditions, leaving the possibility to guess the order of condition averages from the spread.

It may be suprising that the log-normal-based procedure does not perfectly equalize the condition means or medians, @fig-pilot-data-rt C.
Means are not equalized because the log-normal distribution is skewed.
Medians are not equalized because I did not estimate separate non-decision times $\delta$ for each condition.
Because the median of the response time distribution $\widetilde{y} = \exp(\mu) + \delta$, the non-decision time $\delta$ would have to be estimated separately for each condition to perfectly equalize the medians.
The remaining differences in the medians can inform auxillary modelling assumptions about effects of the experimental factors on the non-decision time.
Importantly, the log-normal-based procedure equalizes the average decision times $\mu$ and adjusts the spread of the distributions---most notably for loss trials when there was an opportunity to cheat.

```{r}
#| label: fig-pilot-data-rt
#| fig-cap: "Response times in the pilot data. (A) Unblinded data, (B) blinded data with equalized condition means, and (C) blinded data with equalized log means $\\mu$ in a three-parameter log-normal distribution. Diamonds represent condition medians, points conditions means, and error bars interquartile ranges. The dashed vertical line represents the grand mean."

pilot_plot <- list(
  geom_violin()
  , geom_sina()
  , stat_summary(geom = "vline", aes(y = 0, xintercept = after_stat(x), group = 1), fun = mean, linetype = "22", orientation = "y")
  , stat_summary(geom = "pointrange", fun.data = tidybayes::median_qi, fun.args = list(.width = 2/3), shape = 23, position = position_dodge(0.9), size = 1.25, color = "white")
  , stat_summary(geom = "point", fun = mean, shape = 21, position = position_dodge(0.9), size = 2, color = "white")
  , xlim(0, 2300)
  , labs(x = "Response time [ms]", y = "Condition")
)

rt_plot <- ggplot(pilot) +
  aes(x = rt, y = condition, fill = correct) +
  pilot_plot

naive_blinded_rt_plot <- ggplot(blinded_pilot) +
  aes(x = naive_rt, y = condition, fill = correct) +
  pilot_plot

blinded_rt_plot <- ggplot(blinded_pilot) +
  aes(x = rt, y = condition, fill = correct) +
  pilot_plot

(plot_spacer() + rt_plot + plot_spacer() + plot_layout(widths = c(0.5, 1.25, 0.5))) /
  (naive_blinded_rt_plot | blinded_rt_plot) +
  plot_layout(guides = "collect") +
  plot_annotation(tag_levels = "A")
```


This same general procedure can be used to create a second version of the blinded data that approximately replicates the size of the effects reported by Paxton & Greene (2009).

# Extension to hierarchical data

To accomodate the hierarchical nature of the data, many sophisticated solutions are conceivable.
After due considerations, I opted to take a simple approach that equalizes condition means and average decision times as well as any heterogeneity in effects between participants.
It's understood that such heterogeneity is likely to be present in the data.
What is more, it seems likely that the magnitude of the heterogenity is correlated with the size of the average effect.
Hence, to avoid leaking information about the average effects into the blinded data, I opted to equalize means and average decision times at the participant level.
This approach also works with minimal assumptions when participants provide no observations is some conditions (complete dishonesty in the opportunity condition).

To demonstrate this procedure, I simulated data for 10 participants from a three-parameter log-normal model.

```{r}
#| label: simulate-hierarchical-data
#| cache: true

set.seed(27896)

n <- 10

# Dishonesty scores ----

# curve(dbeta((x - 0.5) / 0.5, 0.5, 0.5), 0, 1)
dishonesty <- round((rbeta(n, 0.5, 0.5) + 0.5) / 1.5, 2)

# Response time parmeters ----

# curve(dshifted_lnorm(x, meanlog = log(0.200), sdlog = 1/2), 0, 0.5)
ndt <- log(0.2)
sd_ndt <- 1/2

# curve(dshifted_lnorm(x, meanlog = -0.5, sdlog = 1/2), 0, 2)
sigma <- -0.5
sigma_sd <- 0.5

# curve(dshifted_lnorm(x, meanlog = -0.75, sdlog = 1/3), 0, 1.5)
b_0 <- -0.75
sd_0 <- 1/3

b_condition <- -0.5
b_correct <- 0.33
b_cond_cor <- -0.3

sd_condition  <- 0.2
sd_correct <- 0.2
sd_cond_cor <- 0.2

ndt_i <- rshifted_lnorm(n, meanlog = ndt, sdlog = sd_ndt)
rt_sigma_i <- rshifted_lnorm(n, meanlog = sigma, sdlog = sigma_sd)
rt_b_0_i <- rnorm(n, mean = b_0, sd = sd_0)

rt_b_condition_i <- rnorm(n, mean = b_condition, sd = sd_condition)
rt_b_correct_i <- rnorm(n, mean = b_correct, sd = sd_correct)
rt_b_cond_cor_i <- rnorm(n, mean = b_cond_cor, sd = sd_cond_cor)

# fMRI data parameters ----

b_0 <- 0
fmri_sigma <- 1

b_condition <- -0.5
b_correct <- 0.33
b_cond_cor <- -0.3

sd_condition  <- 0.3
sd_correct <- 0.3
sd_cond_cor <- 0.3

fmri_b_0_i <- rep(b_0, n)
fmri_b_condition_i <- rnorm(n, mean = b_condition, sd = sd_condition)
fmri_b_correct_i <- rnorm(n, mean = b_correct, sd = sd_correct)
fmri_b_cond_cor_i <- rnorm(n, mean = b_cond_cor, sd = sd_cond_cor)

design <- expand.grid(
  condition = c("op", "noop")
  , correct = c("loss", "win")
) |>
  dplyr::mutate(
    condition_c = dplyr::if_else(condition == "noop", 1, -1)
    , correct_c = dplyr::if_else(correct == "loss", 1, -1)
    , cond_cor_c = condition_c * correct_c
  ) |>
  tidyr::crossing(id = 1:n)

coef <- data.frame(
  id = 1:n
  , dishonesty = dishonesty
  , ndt = ndt_i
  , rt_sigma = rt_sigma_i
  , rt_b_0 = rt_b_0_i
  , rt_b_condition = rt_b_condition_i
  , rt_b_correct = rt_b_correct_i
  , rt_b_cond_cor = rt_b_cond_cor_i
  , fmri_sigma = fmri_sigma
  , fmri_b_0 = fmri_b_0_i
  , fmri_b_condition = fmri_b_condition_i
  , fmri_b_correct = fmri_b_correct_i
  , fmri_b_cond_cor = fmri_b_cond_cor_i
)

synth_dat <- dplyr::left_join(
  design
  , coef
  , by = "id"
) |>
  dplyr::mutate(
    n = dplyr::if_else(
      condition == "noop"
      , 35
      , dplyr::if_else(
        correct == "win"
        , round(dishonesty * 70)
        , 70 - round(dishonesty * 70)
      )
    )
  ) |>
  dplyr::rowwise() |>
  dplyr::mutate(
    rt = rshifted_lnorm(
      n
      , meanlog = rt_b_0 + condition_c * rt_b_condition + correct_c * rt_b_correct +
        rt_b_cond_cor * cond_cor_c
      , sdlog = rt_sigma
      , shift = ndt
    ) |> list(rt = _)
    , dlpfc_activity = rnorm(
      n
      , mean = fmri_b_0 + condition_c * fmri_b_condition - correct_c * fmri_b_correct -
        fmri_b_cond_cor * cond_cor_c
      , sd = fmri_sigma * 2
    ) |> list(dlpfc_activity = _)
    , acc_activity = rnorm(
      n
      , mean = fmri_b_0 + condition_c * fmri_b_condition + correct_c * fmri_b_correct +
        fmri_b_cond_cor * cond_cor_c
      , sd = fmri_sigma
    ) |> list(acc_activity = _)
    , id = factor(id)
  ) |>
  tidyr::unnest(cols = c("rt", "dlpfc_activity", "acc_activity")) |>
  dplyr::ungroup() |>
  dplyr::select(
    -c(ndt:fmri_b_cond_cor)
    , -dplyr::ends_with("_c")
    , -n
  )
```

Notice here, that we have see no losses in the opportunity condition for `r sum(dishonesty == 1)` participants.
@fig-synth-data shows the condition means for the average of all 10 participants and for simulated participant 1.

```{r}
#| label: fig-synth-data
#| fig-cap: "Simulated response times, fMRI bold signal in the DLPFC, and ACC for 50 participants. Points represent condition medians and error bars interquartile range."

synth_dat_peek <- summarize(
  synth_dat
  , rt = mean(rt)
  , acc_activity = mean(acc_activity)
  , dlpfc_activity = mean(dlpfc_activity)
  , .by = c("id", "condition", "correct")
) |>
  summarize(
    rt = mean_cl_normal(rt)
    , acc_activity = mean_cl_normal(acc_activity)
    , dlpfc_activity = mean_cl_normal(dlpfc_activity)
    , .by = c("condition", "correct")
  ) |>
  mutate(id = "Average") |>
  full_join(
    summarize(
      synth_dat
      , rt = mean_cl_normal(rt)
      , acc_activity = mean_cl_normal(acc_activity)
      , dlpfc_activity = mean_cl_normal(dlpfc_activity)
      , .by = c("id", "condition", "correct")
    )
  ) |>
  tidyr::pivot_longer(
    cols = c(rt, acc_activity, dlpfc_activity)
    , names_to = "measure"
    , values_to = "value"
  )

filter(synth_dat_peek, id %in% c("Average", 1)) |>
  ggplot() +
    aes(y = condition, fill = correct) +
    geom_pointrange(
      aes(x = value$y, xmin = value$ymin, xmax = value$ymax)
      , orientation = "y", shape = 21, size = 1.25, position = position_dodge(0.5)
    ) +
    labs(x = NULL) +
    facet_grid(id ~ measure, scales = "free_x") +
    labs(y = "Condition")
```

With the functions in this package, it's straight forward to apply the blinding procedure outline above to the data of each subject.

First, I create a combined factor for `condition` and `correct` to ensure that the procedure works when cells are empty.
Next, I precompile the model used to equalize average decision times to speed up the process.
I then apply the blinding procedure to the merged data of each participant.
Finally, I shuffle the participant-level predictor `dishonesty` to obfuscate the relationship between dishonesty and the experimental conditions.
This is pointless in this case, because the dishonesty score can be recalculated from the number of `win` responses in the `op`-condition, but the same procedure can be applied to other independent predictors of cheating behavior.

```{r}
#| label: blinding-hierarchical-data

library("reppag2009")

synth_dat <- synth_dat |>
  dplyr::mutate(int = interaction(condition, correct))

lnorm_mod <- brms::brm(
  rt ~ int
  , family = brms::shifted_lognormal
  , data = synth_dat
  , warmup = 1
  , iter = 2
  , refresh = 0
  , silent = 0
) |>
  suppressWarnings()

blinded_synth_dat <- synth_dat |>
  reppag2009::equalize_means(
    cbind(acc_activity, dlpfc_activity) ~ id * condition * correct
  ) |>
  dplyr::reframe(
    reppag2009::equalize_logmeans(
      dplyr::pick(dplyr::everything())
      , brmsfit = lnorm_mod
      , warmup = 1000 
      , iter = 2000
      , cores = 2
      , chains = 4
      , refresh = 0
      , silent = 0
    )
    , .by = id
  ) |>
  reppag2009::shuffle_variable(dishonesty ~ id) |>
  dplyr::select(-int)
```

@fig-blinded-synth-data shows the condition means for the average of all 10 participants and for simulated participant 1.

```{r}
#| label: fig-blinded-synth-data
#| fig-cap: "Blinded simulated response times, fMRI bold signal in the DLPFC, and ACC for 50 participants. Points represent condition medians and error bars interquartile range."

blinded_synth_dat_peek <- summarize(
  blinded_synth_dat
  , rt = mean(rt)
  , acc_activity = mean(acc_activity)
  , dlpfc_activity = mean(dlpfc_activity)
  , .by = c("id", "condition", "correct")
) |>
  summarize(
    rt = mean_cl_normal(rt)
    , acc_activity = mean_cl_normal(acc_activity)
    , dlpfc_activity = mean_cl_normal(dlpfc_activity)
    , .by = c("condition", "correct")
  ) |>
  mutate(id = "Average") |>
  full_join(
    summarize(
      blinded_synth_dat
      , rt = mean_cl_normal(rt)
      , acc_activity = mean_cl_normal(acc_activity)
      , dlpfc_activity = mean_cl_normal(dlpfc_activity)
      , .by = c("id", "condition", "correct")
    )
  ) |>
  tidyr::pivot_longer(
    cols = c(rt, acc_activity, dlpfc_activity)
    , names_to = "measure"
    , values_to = "value"
  )

filter(blinded_synth_dat_peek, id %in% c("Average", 1)) |>
  ggplot() +
    aes(y = condition, fill = correct) +
    geom_pointrange(
      aes(x = value$y, xmin = value$ymin, xmax = value$ymax)
      , orientation = "y", shape = 21, size = 1.25, position = position_dodge(0.5)
    ) +
    labs(x = NULL) +
    facet_grid(id ~ measure, scales = "free_x") +
    labs(y = "Condition")
```


# Application to real data

To apply this workflow to the real data, I provide a convenience function `read_raw_data()` to read in all XLSX-files in a given directory.
The only assumption made here is that the response time data is in a column named `behavioral_response`, as was the case for the pilot data.

```{r}
#| label: blinding-individual-dataframes
#| code-fold: false
#| eval: false

reppag2009_data <- reppag2009::read_raw_data("./path/to/xlsx_files") |>
  dplyr::mutate(int = interaction(condition, correct))

lnorm_mod <- brms::brm(
  rt ~ int
  , family = brms::shifted_lognormal
  , data = reppag2009_data
  , warmup = 1
  , iter = 2
) |>
  suppressWarnings()

blinded_reppag2009_data <- reppag2009_data |>
  reppag2009::equalize_means(
    cbind(acc_activity, dlpfc_activity) ~ id * condition * correct
  ) |>
  dplyr::reframe(
    {
      cat("Equalizing:", dplyr::cur_group_id(), "\n")
      reppag2009::equalize_logmeans(
        dplyr::pick(dplyr::everything())
        , brmsfit = lnorm_mod
        , warmup = 1000 
        , iter = 2000
        , cores = 2
        , chains = 4
        , refresh = 0
      )
    }
    , .by = id
  ) |>
  reppag2009::shuffle_variable(dishonesty ~ id) |>
  dplyr::select(-int)

saveRDS(
  blinded_reppag2009_data
  , "blinded_reppag2009_data.rds"
)
```
